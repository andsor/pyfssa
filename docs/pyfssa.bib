@article{Kolda2003Optimization,
    abstract = {Direct search methods are best known as unconstrained optimization techniques that do not explicitly use derivatives. Direct search methods were formally proposed and widely applied in the 1960s but fell out of favor with the mathematical optimization community by the early 1970s because they lacked coherent mathematical analysis. Nonetheless, users remained loyal to these methods, most of which were easy to program, some of which were reliable. In the past fifteen years, these methods have seen a revival due, in part, to the appearance of mathematical analysis, as well as to interest in parallel and distributed computing.

This review begins by briefly summarizing the history of direct search methods and considering the special properties of problems for which they are well suited. Our focus then turns to a broad class of methods for which we provide a unifying framework that lends itself to a variety of convergence results. The underlying principles allow generalization to handle bound constraints and linear constraints. We also discuss extensions to problems with nonlinear constraints.},
    author = {Kolda, Tamara G. and Lewis, Robert M. and Torczon, Virginia},
    citeulike-article-id = {9942868},
    citeulike-linkout-0 = {http://dx.doi.org/10.1137/s003614450242889},
    doi = {10.1137/s003614450242889},
    journal = {SIAM Review},
    keywords = {optimization},
    number = {3},
    pages = {385--482},
    posted-at = {2014-09-05 18:54:00},
    priority = {0},
    title = {Optimization by Direct Search: New Perspectives on Some Classical and Modern Methods},
    url = {http://dx.doi.org/10.1137/s003614450242889},
    volume = {45},
    year = {2003}
}

@article{Lagarias1998Convergence,
    abstract = {The {Nelder--Mead} simplex algorithm, first published in 1965, is an enormously popular direct search method for multidimensional unconstrained minimization. Despite its widespread use, essentially no theoretical results have been proved explicitly for the {Nelder--Mead} algorithm. This paper presents convergence properties of the {Nelder--Mead} algorithm applied to strictly convex functions in dimensions 1 and 2. We prove convergence to a minimizer for dimension 1, and various limited convergence results for dimension 2. A counterexample of {McKinnon} gives a family of strictly convex functions in two dimensions and a set of initial conditions for which the {Nelder--Mead} algorithm converges to a nonminimizer. It is not yet known whether the {Nelder--Mead} method can be proved to converge to a minimizer for a more specialized class of convex functions in two dimensions.},
    author = {Lagarias, Jeffrey C. and Reeds, James A. and Wright, Margaret H. and Wright, Paul E.},
    citeulike-article-id = {3130144},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=588893.589108},
    citeulike-linkout-1 = {http://dx.doi.org/10.1137/s1052623496303470},
    doi = {10.1137/s1052623496303470},
    journal = {SIAM Journal on Optimization},
    keywords = {optimization},
    number = {1},
    pages = {112--147},
    posted-at = {2014-09-05 18:53:55},
    priority = {0},
    title = {Convergence Properties of the {Nelder--Mead} Simplex Method in Low Dimensions},
    url = {http://dx.doi.org/10.1137/s1052623496303470},
    volume = {9},
    year = {1998}
}

@article{Spendley1962Sequential,
    abstract = {A technique for empirical optimisation is presented in which a sequence of experimental designs each in the form of a regular or irregular simplex is used, each simplex having all vertices but one in common with the preceding simplex, and being completed by one new point. Reasons for the choice of design are outlined, and a formal procedure given. The performance of the technique in the presence and absence of error is studied and it is shown (a) that in the presence of error the rate of advance is inversely proportional to the error standard deviation, so that replication of observations is not beneficial, and (b) that the ?efficiency? of the technique appears to increase in direct proportion to the number of factors investigated. It is also noted that, since the direction of movement from each simplex is dependent solely on the ranking of the observations, the technique may be used even in circumstances when a response cannot be quantitatively assessed. Attention is drawn to the ease with which second-order designs having the minimum number of experimental points may be derived from a regular simplex, and a fitting procedure which avoids a direct matrix inversion is suggested. In a brief appendix one or two new rotatable designs derivable from a simplex are noted.},
    author = {Spendley, W. and Hext, G. R. and Himsworth, F. R.},
    citeulike-article-id = {13344006},
    citeulike-linkout-0 = {http://dx.doi.org/10.1080/00401706.1962.10490033},
    citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/00401706.1962.10490033},
    doi = {10.1080/00401706.1962.10490033},
    journal = {Technometrics},
    keywords = {optimization},
    number = {4},
    pages = {441--461},
    posted-at = {2014-09-05 18:53:51},
    priority = {0},
    title = {Sequential Application of Simplex Designs in Optimisation and Evolutionary Operation},
    url = {http://dx.doi.org/10.1080/00401706.1962.10490033},
    volume = {4},
    year = {1962}
}

@article{Singer2004Efficient,
    abstract = {The {Nelder–Mead} or simplex search algorithm is one of the best known algorithms for unconstrained optimization of non–smooth functions. Even though the basic algorithm is quite simple, it is implemented in many different ways. Apart from some minor computational details, the main difference between various implementations lies in the selection of convergence (or termination) tests, which are used to break the iteration process. A fairly simple efficiency analysis of each iteration step reveals a potential computational bottleneck in the domain convergence test. To be efficient, such a test has to be sublinear in the number of vertices of the working simplex. We have tested some of the most common implementations of the {Nelder–Mead} algorithm, and none of them is efficient in this sense.

Therefore, we propose a simple and efficient domain convergence test and discuss some of its properties. This test is based on tracking the volume of the working simplex throughout the iterations. Similar termination tests can also be applied in some other simplex–based direct search methods.},
    author = {Singer, Sa\v{s}a and Singer, Sanja},
    citeulike-article-id = {13344005},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/anac.200410015},
    doi = {10.1002/anac.200410015},
    journal = {Applied Numerical Analysis \& Computational Mathematics},
    keywords = {optimization},
    number = {2},
    pages = {524--534},
    posted-at = {2014-09-05 18:53:46},
    priority = {0},
    title = {Efficient Implementation of the {Nelder-Mead} Search Algorithm},
    url = {http://dx.doi.org/10.1002/anac.200410015},
    volume = {1},
    year = {2004}
}

@article{Price2002Convergent,
    abstract = {The {Nelder–Mead} algorithm (1965) for unconstrained optimization has been used extensively to solve parameter estimation and other problems. Despite its age, it is still the method of choice for many practitioners in the fields of statistics, engineering, and the physical and medical sciences because it is easy to code and very easy to use. It belongs to a class of methods which do not require derivatives and which are often claimed to be robust for problems with discontinuities or where the function values are noisy. Recently (1998), it has been shown that the method can fail to converge or converge to nonsolutions on certain classes of problems. Only very limited convergence results exist for a restricted class of problems in one or two dimensions. In this paper, a provably convergent variant of the {Nelder–Mead} simplex method is presented and analyzed. Numerical results are included to show that the modified algorithm is effective in practice.},
    author = {Price, C. J. and Coope, I. D. and Byatt, D.},
    citeulike-article-id = {13344003},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/a\%253a1014849028575},
    citeulike-linkout-1 = {http://link.springer.com/article/10.1023/A\%3A1014849028575},
    doi = {10.1023/a\%253a1014849028575},
    journal = {Journal of Optimization Theory and Applications},
    keywords = {optimization},
    number = {1},
    pages = {5--19},
    posted-at = {2014-09-05 18:53:41},
    priority = {0},
    title = {A Convergent Variant of the {Nelder–Mead} Algorithm},
    url = {http://dx.doi.org/10.1023/a\%253a1014849028575},
    volume = {113},
    year = {2002}
}

@article{Oliphant2007Python,
    abstract = {By itself, Python is an excellent "steering" language for scientific codes written in other languages. However, with additional basic tools, Python transforms into a high-level language suited for scientific and engineering code that's often fast enough to be immediately useful but also flexible enough to be sped up with additional extensions.},
    author = {Oliphant, Travis E.},
    citeulike-article-id = {5662279},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/MCSE.2007.58},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/mcse.2007.58},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4160250},
    doi = {10.1109/mcse.2007.58},
    journal = {Computing in Science \&amp; Engineering},
    keywords = {scientific\_computing},
    number = {3},
    pages = {10--20},
    posted-at = {2014-09-05 18:53:36},
    priority = {2},
    title = {Python for Scientific Computing},
    url = {http://dx.doi.org/10.1109/mcse.2007.58},
    volume = {9},
    year = {2007}
}

@misc{Jones2001SciPy,
    author = {Jones, Eric and Oliphant, Travis and Peterson, Pearu},
    citeulike-article-id = {13344001},
    citeulike-linkout-0 = {http://www.scipy.org},
    keywords = {scientific\_computing},
    note = {http://www.scipy.org/},
    posted-at = {2014-09-05 18:53:33},
    priority = {0},
    title = {{SciPy}: Open source scientific tools for {Python}},
    url = {http://www.scipy.org},
    year = {2001--}
}

@article{Nelder1965Simplex,
    abstract = {A method is described for the minimization of a function of n variables, which depends on the comparison of function values at the (n + 1) vertices of a general simplex, followed by the replacement of the vertex with the highest value by another point. The simplex adapts itself to the local landscape, and contracts on to the final minimum. The method is shown to be effective and computationally compact. A procedure is given for the estimation of the Hessian matrix in the neighbourhood of the minimum, needed in statistical estimation problems.},
    author = {Nelder, J. A. and Mead, R.},
    citeulike-article-id = {3009487},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/comjnl/7.4.308},
    citeulike-linkout-1 = {http://comjnl.oxfordjournals.org/content/7/4/308.abstract},
    citeulike-linkout-2 = {http://comjnl.oxfordjournals.org/content/7/4/308.full.pdf},
    citeulike-linkout-3 = {http://comjnl.oxfordjournals.org/cgi/content/abstract/7/4/308},
    doi = {10.1093/comjnl/7.4.308},
    journal = {The Computer Journal},
    keywords = {optimization},
    number = {4},
    pages = {308--313},
    posted-at = {2014-09-05 18:53:28},
    priority = {0},
    publisher = {Oxford University Press},
    title = {A Simplex Method for Function Minimization},
    url = {http://dx.doi.org/10.1093/comjnl/7.4.308},
    volume = {7},
    year = {1965}
}

@article{Singer2009NelderMead,
    abstract = {The {Nelder-Mead} algorithm or simplex search algorithm, originally published in 1965 (Nelder and Mead, 1965), is one of the best known algorithms for multidimensional unconstrained optimization without derivatives. This method should not be confused with Dantzig's simplex method for linear programming, which is completely different, as it solves a linearly constrained linear problem.

The basic algorithm is quite simple to understand and very easy to use. For these reasons, it is very popular in many fields of science and technology, especially in chemistry and medicine.

The method does not require any derivative information, which makes it suitable for problems with non-smooth functions. It is widely used to solve parameter estimation and similar statistical problems, where the function values are uncertain or subject to noise. It can also be used for problems with discontinuous functions, which occur frequently in statistics and experimental mathematics.},
    author = {Singer, Sa\v{s}a and Nelder, John},
    citeulike-article-id = {13343996},
    citeulike-linkout-0 = {http://dx.doi.org/10.4249/scholarpedia.2928},
    doi = {10.4249/scholarpedia.2928},
    journal = {Scholarpedia},
    keywords = {optimization},
    number = {7},
    pages = {2928+},
    posted-at = {2014-09-05 18:53:24},
    priority = {0},
    title = {{Nelder-Mead} algorithm},
    url = {http://dx.doi.org/10.4249/scholarpedia.2928},
    volume = {4},
    year = {2009}
}

@misc{Melchert2009AutoScalepy,
    abstract = {{autoScale}.py is a program that performs an automatic finite-size scaling
analysis for given sets of simulated data. It implements a quite general
scaling assumption and optimizes an initial set of scaling parameters that
enforce a data collapse of the different data sets. The presented guide
describes how the program works, it presents a detailed example and finally
gives some hints on how to improve the results of a scaling analysis.},
    archivePrefix = {arXiv},
    author = {Melchert, O.},
    citeulike-article-id = {6994170},
    citeulike-linkout-0 = {http://arxiv.org/abs/0910.5403},
    citeulike-linkout-1 = {http://arxiv.org/pdf/0910.5403},
    eprint = {0910.5403},
    keywords = {computational\_physics, data\_analysis, phase\_transition},
    month = oct,
    posted-at = {2014-09-05 16:13:11},
    priority = {0},
    title = {{autoScale}.py - A program for automatic finite-size scaling analyses: A user's guide},
    url = {http://arxiv.org/abs/0910.5403},
    year = {2009}
}

@book{Strutz2011Data,
    address = {Wiesbaden},
    author = {Strutz, Tilo},
    citeulike-article-id = {13341905},
    citeulike-linkout-0 = {http://www.worldcat.org/isbn/9783834810229},
    citeulike-linkout-1 = {http://books.google.com/books?vid=ISBN9783834810229},
    citeulike-linkout-2 = {http://www.amazon.com/gp/search?keywords=9783834810229\&index=books\&linkCode=qs},
    citeulike-linkout-3 = {http://www.librarything.com/isbn/9783834810229},
    citeulike-linkout-4 = {http://www.worldcat.org/oclc/794709654},
    isbn = {9783834810229},
    keywords = {data\_analysis, statistics, textbook},
    posted-at = {2014-09-05 16:12:51},
    priority = {0},
    publisher = {Vieweg + Teubner},
    title = {Data fitting and uncertainty : a practical introduction to weighted least squares and beyond},
    url = {http://www.worldcat.org/isbn/9783834810229},
    year = {2011}
}

@book{Bevington2003Data,
    address = {Boston},
    author = {Bevington, Philip R. and Robinson, D. Keith},
    citeulike-article-id = {13342054},
    edition = {Third},
    keywords = {data\_analysis, textbook},
    posted-at = {2014-09-05 16:12:40},
    priority = {0},
    publisher = {McGraw-Hill},
    title = {Data Reduction and Error Analysis for the Physical Sciences},
    year = {2003}
}

@article{Wenzel2008Percolation,
    abstract = {The compact Abelian Higgs model is simulated on a cubic lattice where it possesses vortex lines and pointlike magnetic monopoles as topological defects. The focus of this high-precision Monte Carlo study is on the vortex network, which is investigated by means of percolation observables. In the region of the phase diagram where the Higgs and confinement phases are separated by a first-order transition, it is shown that the vortices percolate right at the phase boundary, and that the first-order nature of the transition is reflected by the network. In the crossover region, where the phase boundary ceases to be first order, the vortices are shown to still percolate. In contrast to other observables, the percolation observables show finite-size scaling. The exponents characterizing the critical behavior of the vortices in this region are shown to fall in the random percolation universality class.},
    author = {Wenzel, Sandro and Bittner, Elmar and Janke, Wolfhard and Schakel, Adriaan M. J.},
    citeulike-article-id = {13343945},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.nuclphysb.2007.10.024},
    doi = {10.1016/j.nuclphysb.2007.10.024},
    journal = {Nuclear Physics B},
    keywords = {data\_analysis, percolation, phase\_transition},
    pages = {344--361},
    posted-at = {2014-09-05 16:12:12},
    priority = {0},
    title = {Percolation of vortices in the {3D} Abelian lattice Higgs model},
    url = {http://dx.doi.org/10.1016/j.nuclphysb.2007.10.024},
    volume = {793},
    year = {2008}
}

@article{Bhattacharjee2001Measure,
    abstract = {Data collapse is a way of establishing scaling and extracting associated exponents in problems showing self-similar or self-affine characteristics as, for example, in equilibrium or non-equilibrium phase transitions, in critical phases, in dynamics of complex systems and many others.  We propose a measure to quantify the nature of data collapse. Via a minimization of this measure, the exponents and their error-bars can be obtained.  The procedure is illustrated by considering finite-size-scaling near phase transitions and quite strikingly recovering the exact exponents.},
    author = {Bhattacharjee, Somendra M. and Seno, Flavio},
    citeulike-article-id = {4139720},
    citeulike-linkout-0 = {http://dx.doi.org/10.1088/0305-4470/34/33/302},
    citeulike-linkout-1 = {http://iopscience.iop.org/0305-4470/34/33/302},
    doi = {10.1088/0305-4470/34/33/302},
    journal = {Journal of Physics A: Mathematical and General},
    keywords = {data\_analysis, phase\_transition},
    month = aug,
    number = {33},
    pages = {6375--6380},
    posted-at = {2014-09-02 06:46:29},
    priority = {0},
    title = {A measure of data collapse for scaling},
    url = {http://dx.doi.org/10.1088/0305-4470/34/33/302},
    volume = {34},
    year = {2001}
}

@article{Kawashima1993Critical,
    abstract = {The three-dimensional ± J Ising spin glass model is investigated by means of Monte Carlo simulation. In uniform fields of various strength, the {Edwards-Anderson} susceptibility χ {EA} Q is calculated at T =0.9 J which is lower than the transition temperature in the zero-field case. It is found that χ {EA} decreases monotonically when the field strength is increased and that the data do not suggest a phase transition in a finite field. The best parameters for the scaling function of the form {χEA}({H)≃lψχ\~{}EA}(({H−Hc})l−ϕ) are estimated to be H c =0.00(10) J , ψ=2.16(22) and φ=-1.13(6). These results support the hypothesis that the phase transition does not exist in a finite magnetic field. \sloppy},
    author = {Kawashima, Naoki and Ito, Nobuyasu},
    citeulike-article-id = {13341412},
    citeulike-linkout-0 = {http://dx.doi.org/10.1143/jpsj.62.435},
    doi = {10.1143/jpsj.62.435},
    journal = {Journal of the Physical Society of Japan},
    keywords = {phase\_transition},
    number = {2},
    pages = {435--438},
    posted-at = {2014-08-29 22:47:40},
    priority = {0},
    title = {Critical Behavior of the {Three-Dimensional} ±J Model in a Magnetic Field},
    url = {http://dx.doi.org/10.1143/jpsj.62.435},
    volume = {62},
    year = {1993}
}

@article{Houdayer2004Lowtemperature,
    abstract = {We perform Monte Carlo simulations of large two-dimensional Gaussian Ising spin glasses down to very low temperatures {β=1∕T}=50. Equilibration is ensured by using a cluster algorithm including Monte Carlo moves consisting of flipping fundamental excitations. We study the thermodynamic behavior using the Binder cumulant, the spin-glass susceptibility, the distribution of overlaps, the overlap with the ground state, and the specific heat. We confirm that Tc=0. All results are compatible with an algebraic divergence of the correlation length with an exponent ν. We find −1∕ν=−0.295(40), which is compatible with the value for the domain-wall and droplet exponent θ≈−0.29 found previously in ground-state studies. Hence the thermodynamic behavior of this model seems to be governed by one single exponent.},
    author = {Houdayer, J\'{e}r\^{o}me and Hartmann, Alexander},
    citeulike-article-id = {13341409},
    citeulike-linkout-0 = {http://dx.doi.org/10.1103/physrevb.70.014418},
    doi = {10.1103/physrevb.70.014418},
    journal = {Physical Review B},
    keywords = {phase\_transition},
    number = {1},
    pages = {014418+},
    posted-at = {2014-08-29 22:44:10},
    priority = {0},
    title = {Low-temperature behavior of two-dimensional Gaussian Ising spin glasses},
    url = {http://dx.doi.org/10.1103/physrevb.70.014418},
    volume = {70},
    year = {2004}
}

@article{Fisher1972Scaling,
    abstract = {Critical phenomena in films of finite thickness are considered. A detailed scaling theory, with allowance for distinct exponents \\$\\lambda\\$ and \\$\\theta = \\frac{1}{\\nu}\\$ for the critical-point shift and rounding, respectively, is confirmed by exact calculations on d-dimensional ferromagnetic spherical models and ideal Bose fluids with various boundary conditions. Isingmodel results and existing data on real helium films are consistent with the theory.},
    author = {Fisher, Michael E. and Barber, Michael N.},
    citeulike-article-id = {3446348},
    citeulike-linkout-0 = {http://dx.doi.org/10.1103/physrevlett.28.1516},
    citeulike-linkout-1 = {http://link.aps.org/abstract/PRL/v28/i23/p1516},
    citeulike-linkout-2 = {http://link.aps.org/pdf/PRL/v28/i23/p1516},
    doi = {10.1103/physrevlett.28.1516},
    journal = {Physical Review Letters},
    keywords = {phase\_transition},
    number = {23},
    pages = {1516--1519},
    posted-at = {2014-08-29 17:28:33},
    priority = {0},
    title = {Scaling Theory for {Finite-Size} Effects in the Critical Region},
    url = {http://dx.doi.org/10.1103/physrevlett.28.1516},
    volume = {28},
    year = {1972}
}

@book{Binder2010Monte,
    address = {Berlin, Heidelberg},
    author = {Binder, Kurt and Heermann, Dieter W.},
    citeulike-article-id = {13318034},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-03163-2},
    doi = {10.1007/978-3-642-03163-2},
    isbn = {978-3-642-03162-5},
    keywords = {monte\_carlo, phase\_transition, simulation, statistical\_physics, textbook},
    posted-at = {2014-08-29 17:28:14},
    priority = {0},
    publisher = {Springer},
    title = {Monte Carlo Simulation in Statistical Physics},
    url = {http://dx.doi.org/10.1007/978-3-642-03163-2},
    year = {2010}
}

@book{Newman1999Monte,
    abstract = {{This book provides an introduction to Monte Carlo simulations in classical statistical physics and is aimed both at students beginning work in the field and at more experienced researchers who wish to learn more about Monte Carlo methods. The material covered includes methods for both equilibrium and out of equilibrium systems, and common algorithms like the Metropolis and heat-bath algorithms are discussed in detail, as well as more sophisticated ones such as continuous time Monte Carlo, cluster algorithms, multigrid methods, entropic sampling and simulated tempering. Data analysis techniques are also explained starting with straightforward measurement and error-estimation techniques and progressing to topics such as the single and multiple histogram methods and finite size scaling. The last few chapters of the book are devoted to implementation issues, including discussions of such topics as lattice representations, efficient implementation of data structures, multispin coding, parallelization of Monte Carlo algorithms, and random number generation. At the end of the book the authors give a number of example programs demonstrating the applications of these techniques to a variety of well-known models.}},
    author = {Newman, M. E. J. and Barkema, G. T.},
    citeulike-article-id = {1221914},
    citeulike-linkout-0 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&\#38;path=ASIN/0198517971},
    citeulike-linkout-1 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0198517971},
    citeulike-linkout-10 = {http://www.librarything.com/isbn/0198517971},
    citeulike-linkout-11 = {http://www.worldcat.org/oclc/40927360},
    citeulike-linkout-2 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0198517971},
    citeulike-linkout-3 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0198517971},
    citeulike-linkout-4 = {http://www.amazon.jp/exec/obidos/ASIN/0198517971},
    citeulike-linkout-5 = {http://www.amazon.co.uk/exec/obidos/ASIN/0198517971/citeulike00-21},
    citeulike-linkout-6 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0198517971},
    citeulike-linkout-7 = {http://www.worldcat.org/isbn/0198517971},
    citeulike-linkout-8 = {http://books.google.com/books?vid=ISBN0198517971},
    citeulike-linkout-9 = {http://www.amazon.com/gp/search?keywords=0198517971\&index=books\&linkCode=qs},
    isbn = {9780198517979},
    keywords = {monte\_carlo, statistical\_physics, textbook},
    posted-at = {2014-08-29 17:28:05},
    priority = {0},
    publisher = {Oxford University Press},
    title = {Monte Carlo Methods in Statistical Physics},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0198517971},
    year = {1999}
}

